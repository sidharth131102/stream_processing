project:
  id: stream-accelerator
  region: us-central1
  location: us-central1
service_account:
  name: dataflow-stream-sa
  display_name: Dataflow Streaming Service Account (Dev)
  roles:
  - roles/dataflow.worker
  - roles/pubsub.subscriber
  - roles/pubsub.publisher
  - roles/pubsub.viewer
  - roles/bigquery.dataEditor
  - roles/bigquery.jobUser
  - roles/storage.objectAdmin
  - roles/artifactregistry.reader
storage:
  buckets:
  - name: stream-accelerator-config
    description: Configuration files storage
    files:
    - source: config/source_mapping.yaml
      destination: source_mapping.yaml
    - source: config/destination_mapping.yaml
      destination: destination_mapping.yaml
    - source: config/transformation.yaml
      destination: transformation.yaml
    - source: config/validation.yaml
      destination: validation.yaml
  - name: stream-accelerator-dataflow
    description: Dataflow job artifacts
    folders:
    - staging
    - temp
    - templates
pubsub:
  schemas:
  - name: json_event_v2
    type: avro
    definition_file: schemas/json_event_v2.avsc
  topics:
  - name: json-events-topic
    description: Main events ingestion topic
    schema: json_event_v2
    message_encoding: json
  - name: json-events-dlq
    description: Dead letter queue topic
  subscriptions:
  - name: json-events-sub
    topic: json-events-topic
    ack_deadline: 60
    max_delivery_attempts: 5
    dead_letter_topic: json-events-dlq
  - name: json-events-dlq-sub
    topic: json-events-dlq
    ack_deadline: 60
bigquery:
  datasets:
  - name: analytics
    description: Analytics dataset for processed events
    location: us-central1
    tables:
    - name: service_requests
docker:
  registry:
    location: us-central1
    repository: dataflow-accelerators
  image:
    name: json-stream-accelerator
    tag: v66
    dockerfile: docker/Dockerfile
    context: .
dataflow:
  template:
    name: json-streaming-templ-new
    metadata_file: docker/metadata.json
    sdk_language: PYTHON
    storage_path: gs://stream-accelerator-dataflow/templates/json-streaming-templ-new.json
  job:
    name_prefix: json-streaming
    worker_region: us-central1
    worker_zone: us-central1-a
    staging_location: gs://stream-accelerator-dataflow/staging
    temp_location: gs://stream-accelerator-dataflow/temp
    parameters:
      subscription: projects/stream-accelerator/subscriptions/json-events-sub
      config_bucket: stream-accelerator-config
      env: dev
      job_mode: streaming
    num_workers: 2
    max_workers: 5
    worker_machine_type: e2-standard-2
    disk_size_gb: 50
    autoscaling_algorithm: THROUGHPUT_BASED
    enable_streaming_engine: false
    experiments:
    - use_runner_v2
streaming_tuning:
  dedup:
    enabled: true
    mode: single
    buffer_seconds: 30
    max_state_age_sec: 1800
  sharding:
    num_shards: 32
  windowing:
    enabled: true
    type: fixed
    window_size_sec: 60
    allowed_lateness_sec: 300
  batching:
    bigquery:
      enabled: false
      min_batch_size: 200
      max_batch_size: 1000
pipeline_configs:
  config_directory: config
  bucket: stream-accelerator-config
  files:
  - source_mapping.yaml
  - destination_mapping.yaml
  - transformation.yaml
  - validation.yaml
deployment:
  auto_increment_version: true
  cleanup_old_images: true
  max_image_versions: 5
  enable_monitoring: true
  enable_logging: true
control_planes:
  composer:
    config_bucket: stream-accelerator-config
    config_path: composer.yaml
orchestration:
  dags:
    streaming_start: dataflow_streaming_start
    streaming_stop: dataflow_streaming_stop
    rolling_deploy: dataflow_streaming_rolling_deploy
    recovery: failure_auto_recovery
archive:
  enabled: true
  bucket: stream-accelerator-archive
  path_prefix: gs://stream-accelerator-archive/events
  format: json
schema_management:
  enabled: true
  scope: FULL_EVENT
  schema_name: json_event_v2
  schema_version: v2
  evolution_policy:
    on_new_field: ALLOW
    on_missing_field: WARN
    on_type_change: FAIL
  dlq_on_violation: true
